{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clairemerson/clairemerson.github.io/blob/main/CMerson__Insults_with_Naive_Bayes_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DeYXbqK-rRW"
      },
      "source": [
        "## Classifying text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MejilF82-rRZ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV as gs\n",
        "import sklearn.feature_extraction.text as text\n",
        "import sklearn.naive_bayes as nb\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl6tKSoLKbo6"
      },
      "source": [
        "We turn to applying machine learning classification methods to text. There are\n",
        "no new principles at stake.  In principle, everything is the same as it was for\n",
        "learning how to classify irises.\n",
        "\n",
        "1.  We need to find labeled data; each of the exemplars in the data should be represented with a fixed set of features.  \n",
        "2. We need to split our data and training and test data.  \n",
        "3. We need to train learner on the training data and evaluate it (test it) it on the test data.\n",
        "\n",
        "The problem is that text data is not in a form  that is compatible with\n",
        "what we have learned about classifiers.  The text must be put in a suitable\n",
        "form before a linear model; can be trained on it. \n",
        "\n",
        "**Training**\n",
        "\n",
        "1.  Labeled data must be loaded (into Python).  It should be a sequence of documents T accompanied by a sequence of labels L. \n",
        "2.  Split T and L into training and test groups, yielding T1 and T2; as well as and L1 and L2.\n",
        "2.  Train or a **feature model** on the training data T1 (or in scikit learn terminology **fit** the model **to** the training data).  The feature model inputs the text sequence and outputs a **term-document** matrix suitable for training a linear classifier.  The feature model is called a **vectorizer**\n",
        "(because it turns a document into a vector, a column of numbers).\n",
        "3.  Using the trained vectorizer, transform T1 into a term document matrix M1.\n",
        "4.  Train a linear model $\\mu$ on M1 and L1.\n",
        "\n",
        "**Evaluation**\n",
        "\n",
        "1.  Transform the test data T2 into a term document matrix M2 using the vectorizer fit during step 2 of training;  in particular this means if there are words in the T2 data that were never seen during training, they are ignored in building M2.\n",
        "2.  Use $\\mu$  to classify the texts represented in M2; that is produce a set of predicted labels P2.\n",
        "3.  Compare the actual labels L2 with the predicted labels P2 using standard evaluation metrics such as precision, accuracy, and recall.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qildTjvw-rRb"
      },
      "source": [
        "## Review the steps with insult detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28jZSTW_-rRb"
      },
      "source": [
        "We looked at the insult detection data in  the text classification notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RswXa_oOKbo9"
      },
      "source": [
        "### Training step 1: Loading the data\n",
        "\n",
        "Let's load the CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtGQlB1q-rRc"
      },
      "outputs": [],
      "source": [
        "import os.path\n",
        "site = 'https://raw.githubusercontent.com/gawron/python-for-social-science/master/'\\\n",
        "'text_classification/'\n",
        "#site = 'https://gawron.sdsu.edu/python_for_ss/course_core/book_draft/_static/'\n",
        "df = pd.read_csv(os.path.join(site,\"troll.csv\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3ncLUYx-rRc"
      },
      "source": [
        "Each row is a comment  taken from a blog or online forum. There are three columns: whether the comment is insulting (1) or not (0), the date, and the comment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pFeNaW-m-rRd",
        "outputId": "2aae5dd0-07c2-4329-fc61-837b89f61da0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Insult             Date  \\\n",
              "3942       1  20120502172717Z   \n",
              "3943       0  20120528164814Z   \n",
              "3944       0  20120620142813Z   \n",
              "3945       0  20120528205648Z   \n",
              "3946       0  20120515200734Z   \n",
              "\n",
              "                                                Comment  \n",
              "3942  \"you are both morons and that is never happening\"  \n",
              "3943  \"Many toolbars include spell check, like Yahoo...  \n",
              "3944  \"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...  \n",
              "3945  \"How about Felix? He is sure turning into one ...  \n",
              "3946  \"You're all upset, defending this hipster band...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ccc4db3b-a3ad-4f29-a777-02b6ba3e2f5e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Insult</th>\n",
              "      <th>Date</th>\n",
              "      <th>Comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3942</th>\n",
              "      <td>1</td>\n",
              "      <td>20120502172717Z</td>\n",
              "      <td>\"you are both morons and that is never happening\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3943</th>\n",
              "      <td>0</td>\n",
              "      <td>20120528164814Z</td>\n",
              "      <td>\"Many toolbars include spell check, like Yahoo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3944</th>\n",
              "      <td>0</td>\n",
              "      <td>20120620142813Z</td>\n",
              "      <td>\"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3945</th>\n",
              "      <td>0</td>\n",
              "      <td>20120528205648Z</td>\n",
              "      <td>\"How about Felix? He is sure turning into one ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3946</th>\n",
              "      <td>0</td>\n",
              "      <td>20120515200734Z</td>\n",
              "      <td>\"You're all upset, defending this hipster band...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ccc4db3b-a3ad-4f29-a777-02b6ba3e2f5e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ccc4db3b-a3ad-4f29-a777-02b6ba3e2f5e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ccc4db3b-a3ad-4f29-a777-02b6ba3e2f5e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ibxc3U3K-rRh"
      },
      "source": [
        "Now we define the text sequences $\\mathbf{T}$ and the label sequence  $\\mathbf{L}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wty7pj42-rRh"
      },
      "outputs": [],
      "source": [
        "T = df['Comment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8xJstOo-rRi"
      },
      "outputs": [],
      "source": [
        "L = df['Insult']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvopEbp5KbpB"
      },
      "source": [
        "### Step 2 Split the data and labels into training and test groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LO87pUUKbpB"
      },
      "outputs": [],
      "source": [
        "T1, T2, L1, L2 = train_test_split(T,L)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLyPq0ceKbpB"
      },
      "source": [
        "### Step 3 and 4:  Fit the feature model (vectorizer) to the training data and Transform  it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-fPVjYV-rRl"
      },
      "outputs": [],
      "source": [
        "tf = text.TfidfVectorizer()\n",
        "# Scikit learn has one function that does both fitting and transforming.\n",
        "# M1 is the transformed data\n",
        "# tf is the trained feature model (which will be used to transform the test data)\n",
        "M1 = tf.fit_transform(T1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0wp6RbS-rRo"
      },
      "source": [
        "### Step 5 Training the classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88mG_1C0-rRo"
      },
      "source": [
        "Now, we are going to train a classifier as usual. We first split the data into a train and test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf-3XQDN-rRo"
      },
      "source": [
        "We use a **Bernoulli Naive Bayes classifier**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uj7vvTS--rRo"
      },
      "outputs": [],
      "source": [
        "# Create classifer\n",
        "bnb =nb.BernoulliNB()\n",
        "\n",
        "# Fit (train) the classifier  using the training data and labels\n",
        "bnb.fit(M1, L1);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hypewUEdKbpC"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9YQCFyJKbpG"
      },
      "source": [
        "Evaluate the classifier, first using accuracy (what `.score()` returns)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rewbP2vT-rRp",
        "outputId": "b217a4c3-22fd-4c39-dad4-39526a075741"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7922998986828774"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# vectorize the test data using the vectorizer trained on T1\n",
        "# Notice we DONT call .fit_transform() because that would retrain the vectorizer on the test data\n",
        "# We call .transform() using the trained model to transform the new data.\n",
        "# Words not seen during training will be ignored.\n",
        "M2 = tf.transform(T2)\n",
        "# Classify the data using the trained classisifer and report the accuracy\n",
        "bnb.score(M2, L2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p38bf79W-rRp"
      },
      "source": [
        "Now try re-executing steps 2 through 5.  (Just re-execute the cells)  The results should be the same, right?\n",
        "\n",
        "Well, are they?  \n",
        "\n",
        "What happens:  each training test split produces a different set of test data.  Sometimes the test is harder.\n",
        "Sometimes it's easier.  Or looking at it another way:  Sometimes the training data is a better preparation for the test than others.  \n",
        "\n",
        "To get a realistic view of how our classifier is doing we take the average performance on a  number of \n",
        "train/test splits.  This is called **cross validation**.  We return to that point below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8pBa0uBKbpH"
      },
      "source": [
        "#### Using all three evaluation metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk9SMF61KbpI"
      },
      "source": [
        "First let's get more evaluation numbers, in particular precision and recall.  We do\n",
        "that by calling a method that returns the predicted labels P2, so we can compare\n",
        "L2 and P2 using different evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgMX67JoKbpI",
        "outputId": "2c9f5f36-c9a7-4264-db17-8c4bb6ff8d9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.79 Precision: 0.18 Recall: 0.90\n"
          ]
        }
      ],
      "source": [
        "P2 = bnb.predict(M2)\n",
        "scores = np.array([accuracy_score(P2, L2),\n",
        "                   precision_score(P2, L2),\n",
        "                   recall_score(P2, L2)])\n",
        "print(f'Accuracy: {scores[0]:.2f} Precision: {scores[1]:.2f} Recall: {scores[2]:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCb834m4KbpI"
      },
      "source": [
        "We see that the accuracy is a bit misleading.  There is a serious precision problem.\n",
        "\n",
        "What does that mean in the setting of insult detection?  It means the BNB classifier is a little too\n",
        "eager to call something an insult.  When it flags something as an insult, it\n",
        "is right only 14% of the time.\n",
        "\n",
        "Why would that be?  Think about how the model is trained and what its weakness might be.\n",
        "This is what it means to try to interpret or discuss a model's performance.  Zoom\n",
        "in the model's weakness. Talk about where that weakness comes from."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-bt36GeMpFW"
      },
      "source": [
        "#### Basic train and test loop\n",
        "\n",
        "How to get the average of a number of runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwsayH6F-rRp",
        "outputId": "b47c417d-c9cc-4362-806f-76a9d0eda5dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.77 Precision: 0.16 Recall: 0.89\n"
          ]
        }
      ],
      "source": [
        "def split_fit_and_eval(T,L,test_size=.2):\n",
        "    # This code just collects together the training steps 2-5 + the eval\n",
        "    # That is, It does one training,test., eval run\n",
        "    (T1, T2, L1, L2) = train_test_split(T, L, test_size=test_size)\n",
        "    tf = text.TfidfVectorizer()\n",
        "    M1 = tf.fit_transform(T1)\n",
        "    bnb = nb.BernoulliNB()\n",
        "    bnb.fit(M1,L1)\n",
        "    # .fit(), ..fit_transform()\n",
        "    M2 = tf.transform(T2)\n",
        "    P2 = bnb.predict(M2)\n",
        "    return np.array([accuracy_score(P2,L2),\n",
        "                     precision_score(P2, L2),\n",
        "                     recall_score(P2,L2)])\n",
        "\n",
        "# Split, Train, test and eval 10 times\n",
        "num_runs = 10\n",
        "# an accumulator for acc.,pre.,and rec.\n",
        "scores = np.zeros((3,))\n",
        "for test_run in range(num_runs):\n",
        "    scores += split_fit_and_eval(T,L)\n",
        "# Compute the average of the num_runs runs for all metrics\n",
        "normed_stats = scores/num_runs\n",
        "\n",
        "print(f'Accuracy: {normed_stats[0]:.2f} Precision: {normed_stats[1]:.2f} Recall: {normed_stats[2]:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qge21OrOURv4",
        "outputId": "8b12793b-2d6a-4adf-e8ad-08d47f53ed32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "zaE0KDK5-rRr"
      },
      "source": [
        "## Homework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg50G61U-rRr"
      },
      "source": [
        "Read the on line book draft chapter about text classification and and especially\n",
        "about  movie review data.  Note that you will be using a different classifier implementation (`scikit_learn`) than the one used in the book\n",
        "(`nltk`).  Therefore, when it comes to writing code for training the calssifier. focus on the code examples in this notebook, which use `scikit_learn`.\n",
        "\n",
        "Try using two classifiers on the movie review data, the one used in the textbook, an SVM, and\n",
        "the Bernoulli Naive Bayes model used above. Be sure\n",
        "to stick with  scikit learn (it has an SVM implementation).\n",
        "Some points of emphasis;\n",
        "\n",
        "1.  Be sure to get the average of at runs  least 10 runs for **both** classifiers.\n",
        "2.  Be sure to get average accuracy, precision, and recall for both classifiers on those multiple runs. You will probably find `split_fit_and_eval` defined above useful, but you may need to modify it.\n",
        "3.  For your first discussion post turn in the new code you wrote, including the code that labels and shuffles the data (discussed further below).  If you have to do a new import, show that. If you have to rewrite `split_fit_and_eval`, turn in the new version.  Also show the output, which should be a single line giving the accuracy, prcision, and recall.\n",
        "4.  Discuss which classifier does better.  Discuss which metric the best classifier does the worst at and speculate as to why (this will require reviewing the definitions of precision and recall and thinking about what they mean in a movie review setting)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_wazBGWTsS4"
      },
      "source": [
        "#### Help with getting the movie reviews data.\n",
        "\n",
        "Execute the next two cells to get the movie review data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xvlkaI1x-rRr",
        "outputId": "188d05d7-ad68-43fd-8617-ea0cc7258b24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nQdcr4aH_dP"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import movie_reviews as mr\n",
        "\n",
        "def get_file_strings (corpus, file_ids):\n",
        "    return [corpus.raw(file_id) for file_id in file_ids]\n",
        "\n",
        "data = dict(pos = mr.fileids('pos'),\n",
        "            neg = mr.fileids('neg'))\n",
        "\n",
        "pos_file_ids = data['pos']\n",
        "neg_file_ids = data['neg']\n",
        "\n",
        "# Get all the positive and negative reviews.\n",
        "pos_file_reviews = get_file_strings (mr, pos_file_ids)\n",
        "neg_file_reviews = get_file_strings (mr, neg_file_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PY6_uHMJvqC"
      },
      "source": [
        "Each review is a string.  In principle, a list of strings like `pos_file_reviews`  can be passed to `text.TfidfVectorizer()` via the `fit_transform` method to train a vectorizer for machine learning.\n",
        "You could code that up.\n",
        "\n",
        "What you'd really like to do is use `split_fit_and_eval`, defined above, which does a lot of the work for you.\n",
        "\n",
        "But hold on. You have a coding problem. You don't have  a sequence of documents and labels.  Instead you have\n",
        "one sequence of positive documents  and another sequence of negative documents.  \n",
        "\n",
        "So you will need to turn those two sequences into a sequence of documents and a sequence of labels\n",
        "because that's what `split_fit_and_eval` wants.  You also want the doc sequence\n",
        "to contain a random mixture of positive and negative documents, because some machine\n",
        "learning algorithms are sensitive to the order in which training data is presented to\n",
        "them.\n",
        "\n",
        "The next cell does **not** do that for you.  But it illustrates an approach using \n",
        "two sets of English letters in place of two sets of English documents."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifier 1: Bernoulli Naive Bayes model"
      ],
      "metadata": {
        "id": "mC31GDjEbALT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pos_file_reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKYZ0SvWVYyh",
        "outputId": "9ee18ae9-d908-4ecd-bf4e-709185aa825b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify.scikitlearn import LabelEncoder\n",
        "from random import shuffle\n",
        "# Now get pairs of letters and labels\n",
        "pos = [(string,1) for string in pos_file_reviews]\n",
        "neg = [(string,0) for string in neg_file_reviews]\n",
        "\n",
        "###########  Shuffling  ###########################\n",
        "# Way too orderly, the classes arent mixed yet.\n",
        "data = pos + neg\n",
        "shuffle(data)\n",
        "###################  Now they're shuffled! ###############\n",
        "\n",
        "# Separate the Movie Reviews from their labels\n",
        "review, label = zip(*data)\n",
        "len(review)\n",
        "len(label)\n",
        "len(data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9aK1tEoRf-4",
        "outputId": "c9dce54b-90cb-491d-e276-42e2068ffe72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T = review\n",
        "L = label"
      ],
      "metadata": {
        "id": "jDTftw82WnUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T1, T2, L1, L2 = train_test_split(T,L)"
      ],
      "metadata": {
        "id": "mjAS8ApQZfKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf = text.TfidfVectorizer()\n",
        "M1 = tf.fit_transform(T1)"
      ],
      "metadata": {
        "id": "7RVGHPFnZ0Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create classifer\n",
        "bnb =nb.BernoulliNB()\n",
        "\n",
        "# Fit (train) the classifier  using the training data and labels\n",
        "bnb.fit(M1, L1);"
      ],
      "metadata": {
        "id": "cM7rFD0kZ29u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M2 = tf.transform(T2)\n",
        "# Classify the data using the trained classisifer and report the accuracy\n",
        "bnb.score(M2, L2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsrMVVovZ7gb",
        "outputId": "7f4f3f4b-4e22-4382-f5c1-9f6630887e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.794"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P2 = bnb.predict(M2)\n",
        "scores = np.array([accuracy_score(P2, L2),\n",
        "                   precision_score(P2, L2),\n",
        "                   recall_score(P2, L2)])\n",
        "print(f'Accuracy: {scores[0]:.2f} Precision: {scores[1]:.2f} Recall: {scores[2]:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV7yz63hZ-xQ",
        "outputId": "1dcd6b15-117a-446e-c5be-881345f3fc7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.79 Precision: 0.68 Recall: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_fit_and_eval(T,L,test_size=.2):\n",
        "    # This code just collects together the training steps 2-5 + the eval\n",
        "    # That is, It does one training,test., eval run\n",
        "    (T1, T2, L1, L2) = train_test_split(T, L, test_size=test_size)\n",
        "    tf = text.TfidfVectorizer()\n",
        "    M1 = tf.fit_transform(T1)\n",
        "    bnb = nb.BernoulliNB()\n",
        "    bnb.fit(M1,L1)\n",
        "    # .fit(), ..fit_transform()\n",
        "    M2 = tf.transform(T2)\n",
        "    P2 = bnb.predict(M2)\n",
        "    return np.array([accuracy_score(P2,L2),\n",
        "                     precision_score(P2, L2),\n",
        "                     recall_score(P2,L2)])\n",
        "\n",
        "# Split, Train, test and eval 10 times\n",
        "num_runs = 10\n",
        "# an accumulator for acc.,pre.,and rec.\n",
        "scores = np.zeros((3,))\n",
        "for test_run in range(num_runs):\n",
        "    scores += split_fit_and_eval(T,L)\n",
        "# Compute the average of the num_runs runs for all metrics\n",
        "normed_stats = scores/num_runs\n",
        "\n",
        "print(f'Accuracy: {normed_stats[0]:.2f} Precision: {normed_stats[1]:.2f} Recall: {normed_stats[2]:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOsQ4iAgayBk",
        "outputId": "c21d90d3-adcb-4931-9286-738f5510b2ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.78 Precision: 0.66 Recall: 0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "99GXbCq3a5hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Go315-ma5Ex"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "94px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}